{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "DAT340, Assignment 5\n",
    "\n",
    "Romain THEODET\n",
    "\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 2 classes.\n",
      "Found 576 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "imgdir = \"data\"\n",
    "imgSize = 64\n",
    "batchSize = 32\n",
    "\n",
    "trainGenerator = data_gen.flow_from_directory(\n",
    "    imgdir + \"/train\",\n",
    "    target_size=(imgSize, imgSize),\n",
    "    batch_size=batchSize,\n",
    "    class_mode=\"binary\",\n",
    "    classes=[\"other\", \"car\"],\n",
    "    seed=12345,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "xTrain, yTrain = trainGenerator.next()\n",
    "\n",
    "validationGenerator = data_gen.flow_from_directory(\n",
    "    imgdir + \"/validation\",\n",
    "    target_size=(imgSize, imgSize),\n",
    "    batch_size=batchSize,\n",
    "    class_mode=\"binary\",\n",
    "    classes=[\"other\", \"car\"],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "xTest, yTest = validationGenerator.next()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "def make_convnet(width: int, height: int, channels: int) -> Model:\n",
    "    model = Sequential([\n",
    "        Conv2D(\n",
    "            32,\n",
    "            kernel_size=(5, 5),\n",
    "            strides=(1, 1),\n",
    "            activation=\"relu\",\n",
    "            input_shape=(width, height, channels)\n",
    "        ), MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=(2, 2)\n",
    "        ), Conv2D(\n",
    "            64,\n",
    "            (5, 5),\n",
    "            activation=\"relu\"\n",
    "        ), MaxPooling2D(\n",
    "            pool_size=(2, 2)\n",
    "        ), Flatten(\n",
    "        ), Dense(\n",
    "            1000,  # 128 ?\n",
    "            activation=\"relu\"\n",
    "        ), Dense(\n",
    "            1,\n",
    "            activation=\"sigmoid\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "cnn = make_convnet(imgSize, imgSize, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "fitInfos = cnn.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    verbose=1,\n",
    "    batch_size=batchSize,\n",
    "    validation_data=(xTest, yTest),\n",
    "    epochs=10,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romain\\AppData\\Local\\Temp\\ipykernel_6860\\703930679.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = cnn.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "trainingBatchSize = int(1600 / batchSize)\n",
    "validationBatchSize = int(576 / batchSize)\n",
    "\n",
    "history = cnn.fit_generator(\n",
    "    trainGenerator,\n",
    "    validation_data=validationGenerator,\n",
    "    steps_per_epoch=trainingBatchSize,\n",
    "    validation_steps=validationBatchSize,\n",
    "    epochs=10,\n",
    "    use_multiprocessing=False\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}